<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.2" />
<title>skygp.gaussian_emulator API documentation</title>
<meta name="description" content="A module of Gaussian process to emulate any function â€¦" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML'></script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>skygp.gaussian_emulator</code></h1>
</header>
<section id="section-intro">
<p>A module of Gaussian process to emulate any function.</p>
<p>A Gaussian process can be used to emulate arbitrary function. In this
project, we are interested in emulating the relation between Skyrme
parameters and any well-behaved (continuous and smooth) physical
observables, such as n/p ratios.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;A module of Gaussian process to emulate any function.

A Gaussian process can be used to emulate arbitrary function. In this
project, we are interested in emulating the relation between Skyrme
parameters and any well-behaved (continuous and smooth) physical
observables, such as n/p ratios.
&#34;&#34;&#34;

import matplotlib as mpl
import matplotlib.pyplot as plt
import numpy as np
import sklearn.gaussian_process as gp

class GaussianEmulator:
    &#34;&#34;&#34;A class of Gaussian emulator.

    Currently, this class is just a wrapper for sklearn.gaussian_process.
    The purpose of this wrapper is so that alternative package for doing
    Gaussian process can easily be substituted later without affect the
    flow that follows after this class.
    &#34;&#34;&#34;

    def __init__(self):
        &#34;&#34;&#34;This creates a Gaussian emulator.

        Currently, this class is only a wrapper around
        `sklearn.GaussianProcessRegreesor`.
        &#34;&#34;&#34;
        self.regressor = gp.GaussianProcessRegressor()
        self.x_train = None
        self.y_train = None

    def set_niterations(self, n_itr):
        &#34;&#34;&#34;This sets the number of training iterations.

        Parameters:
            n_itr : int
                The number of training iterations.
        &#34;&#34;&#34;
        if not isinstance(n_itr, int):
            raise TypeError(&#39;n_itr must be an integer.&#39;)

        self.regressor.n_restarts_optimizer = n_itr

    def fit(self, x_train, y_train):
        &#34;&#34;&#34;This trains the Gaussian emulator from `x_train` and `y_train`.

        Parameters:
            x_train : numpy array, shape (n_train, n_inputs)
                An array containing the inputs of training set.

            y_train : numpy array, shape (n_train, n_outputs)
                An array containing the outputs of training set.

        &#34;&#34;&#34;
        if not isinstance(x_train, np.ndarray):
            raise TypeError(&#39;x_train must be a numpy array.&#39;)
        if not isinstance(y_train, np.ndarray):
            raise TypeError(&#39;y_train must be a numpy array.&#39;)
        if x_train.ndim != 2:
            raise ValueError(&#39;x_train must be two-dimensional.&#39;)
        if y_train.ndim != 2:
            raise ValueError(&#39;y_train must be two-dimensional.&#39;)

        self.x_train = np.copy(x_train)
        self.y_train = np.copy(y_train)
        self.regressor.fit(self.x_train, self.y_train)

    def predict(self, x_test):
        &#34;&#34;&#34;This returns the prediction.

        This is essentially the emulator function when training has
        been done to a satisfactory level.

        Parameters:
            x_test : numpy array, shape (n_train, n_inputs)
                An array containing the inputs of interest.

        Returns:
            y_pred : numpy array, shape (n_train, n_outputs)
                An array containing the outputs predicted by the emulator.
                When training is done correctly, this prediction should be
                very close to the actual outputs, and hence can be used to
                emulator the actual computation that is usually time
                consuming.

        &#34;&#34;&#34;
        if not isinstance(x_test, np.ndarray):
            raise TypeError(&#39;x_test must be a numpy array.&#39;)

        y_pred = self.regressor.predict(x_test)
        return y_pred

    def inspect_training_xslice(self, xslice, ax=None):
        &#34;&#34;&#34;Plot to compare the emulator&#39;s predictions against training data.

        Parameters:
            xslice : int
                The component of `self.x_train` to be plotted.

            ax : matplotlib.axes._subplots.AxesSubplot *optional*
                The matplotlib axe to be plotted.

        Returns:
            ax : matplotlib.axes._subplots.AxesSubplot

        Examples:
        ----------
        After we have trained the `GaussianEmulator`, we may inspect the
        training results as below:

        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; import gaussian_emulator as gmu
        &gt;&gt;&gt; emulator = gmu.GaussianEmulator()
        &gt;&gt;&gt; x_train = np.array([[0.0], [1.0]])
        &gt;&gt;&gt; y_train = np.array([[0.0], [2.0]])
        &gt;&gt;&gt; emulator.fit(x_train, y_train)
        &gt;&gt;&gt; emulator.inspect_training_xslice(0)
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x...&gt;

        &#34;&#34;&#34;
        if not isinstance(xslice, int):
            raise TypeError(&#39;xslice must be an integer.&#39;)
        if ax is not None and not isinstance(ax, mpl.axes.Axes):
            raise TypeError(&#39;ax must be a matplotlib.axes.Axes object.&#39;)

        # create ax if not being passed
        if ax is None:
            _, ax = plt.subplots()

        # sort training data by i_slice
        argsort = np.argsort(self.x_train[:, xslice])
        x_train_sorted = self.x_train[argsort]
        y_train_sorted = self.y_train[argsort]

        y_pred = self.predict(x_train_sorted)
        n_outputs = y_train_sorted.shape[1]
        for i in range(n_outputs):
            if n_outputs &gt; 1:
                color = plt.cm.jet(1.0 * i/(n_outputs-1))
            else:
                color = plt.cm.jet(1.0)
            x_slice = x_train_sorted[:, xslice]
            ax.scatter(x_slice, y_train_sorted[:, i], color=color, label=&#39;y%d true&#39; % i)
            ax.plot(x_slice, y_pred[:, i], color=color, linestyle=&#39;dashed&#39;, label=&#39;y%d pred&#39; % i)
        return ax</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="skygp.gaussian_emulator.GaussianEmulator"><code class="flex name class">
<span>class <span class="ident">GaussianEmulator</span></span>
</code></dt>
<dd>
<section class="desc"><p>A class of Gaussian emulator.</p>
<p>Currently, this class is just a wrapper for sklearn.gaussian_process.
The purpose of this wrapper is so that alternative package for doing
Gaussian process can easily be substituted later without affect the
flow that follows after this class.</p>
<p>This creates a Gaussian emulator.</p>
<p>Currently, this class is only a wrapper around
<code>sklearn.GaussianProcessRegreesor</code>.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GaussianEmulator:
    &#34;&#34;&#34;A class of Gaussian emulator.

    Currently, this class is just a wrapper for sklearn.gaussian_process.
    The purpose of this wrapper is so that alternative package for doing
    Gaussian process can easily be substituted later without affect the
    flow that follows after this class.
    &#34;&#34;&#34;

    def __init__(self):
        &#34;&#34;&#34;This creates a Gaussian emulator.

        Currently, this class is only a wrapper around
        `sklearn.GaussianProcessRegreesor`.
        &#34;&#34;&#34;
        self.regressor = gp.GaussianProcessRegressor()
        self.x_train = None
        self.y_train = None

    def set_niterations(self, n_itr):
        &#34;&#34;&#34;This sets the number of training iterations.

        Parameters:
            n_itr : int
                The number of training iterations.
        &#34;&#34;&#34;
        if not isinstance(n_itr, int):
            raise TypeError(&#39;n_itr must be an integer.&#39;)

        self.regressor.n_restarts_optimizer = n_itr

    def fit(self, x_train, y_train):
        &#34;&#34;&#34;This trains the Gaussian emulator from `x_train` and `y_train`.

        Parameters:
            x_train : numpy array, shape (n_train, n_inputs)
                An array containing the inputs of training set.

            y_train : numpy array, shape (n_train, n_outputs)
                An array containing the outputs of training set.

        &#34;&#34;&#34;
        if not isinstance(x_train, np.ndarray):
            raise TypeError(&#39;x_train must be a numpy array.&#39;)
        if not isinstance(y_train, np.ndarray):
            raise TypeError(&#39;y_train must be a numpy array.&#39;)
        if x_train.ndim != 2:
            raise ValueError(&#39;x_train must be two-dimensional.&#39;)
        if y_train.ndim != 2:
            raise ValueError(&#39;y_train must be two-dimensional.&#39;)

        self.x_train = np.copy(x_train)
        self.y_train = np.copy(y_train)
        self.regressor.fit(self.x_train, self.y_train)

    def predict(self, x_test):
        &#34;&#34;&#34;This returns the prediction.

        This is essentially the emulator function when training has
        been done to a satisfactory level.

        Parameters:
            x_test : numpy array, shape (n_train, n_inputs)
                An array containing the inputs of interest.

        Returns:
            y_pred : numpy array, shape (n_train, n_outputs)
                An array containing the outputs predicted by the emulator.
                When training is done correctly, this prediction should be
                very close to the actual outputs, and hence can be used to
                emulator the actual computation that is usually time
                consuming.

        &#34;&#34;&#34;
        if not isinstance(x_test, np.ndarray):
            raise TypeError(&#39;x_test must be a numpy array.&#39;)

        y_pred = self.regressor.predict(x_test)
        return y_pred

    def inspect_training_xslice(self, xslice, ax=None):
        &#34;&#34;&#34;Plot to compare the emulator&#39;s predictions against training data.

        Parameters:
            xslice : int
                The component of `self.x_train` to be plotted.

            ax : matplotlib.axes._subplots.AxesSubplot *optional*
                The matplotlib axe to be plotted.

        Returns:
            ax : matplotlib.axes._subplots.AxesSubplot

        Examples:
        ----------
        After we have trained the `GaussianEmulator`, we may inspect the
        training results as below:

        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; import gaussian_emulator as gmu
        &gt;&gt;&gt; emulator = gmu.GaussianEmulator()
        &gt;&gt;&gt; x_train = np.array([[0.0], [1.0]])
        &gt;&gt;&gt; y_train = np.array([[0.0], [2.0]])
        &gt;&gt;&gt; emulator.fit(x_train, y_train)
        &gt;&gt;&gt; emulator.inspect_training_xslice(0)
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x...&gt;

        &#34;&#34;&#34;
        if not isinstance(xslice, int):
            raise TypeError(&#39;xslice must be an integer.&#39;)
        if ax is not None and not isinstance(ax, mpl.axes.Axes):
            raise TypeError(&#39;ax must be a matplotlib.axes.Axes object.&#39;)

        # create ax if not being passed
        if ax is None:
            _, ax = plt.subplots()

        # sort training data by i_slice
        argsort = np.argsort(self.x_train[:, xslice])
        x_train_sorted = self.x_train[argsort]
        y_train_sorted = self.y_train[argsort]

        y_pred = self.predict(x_train_sorted)
        n_outputs = y_train_sorted.shape[1]
        for i in range(n_outputs):
            if n_outputs &gt; 1:
                color = plt.cm.jet(1.0 * i/(n_outputs-1))
            else:
                color = plt.cm.jet(1.0)
            x_slice = x_train_sorted[:, xslice]
            ax.scatter(x_slice, y_train_sorted[:, i], color=color, label=&#39;y%d true&#39; % i)
            ax.plot(x_slice, y_pred[:, i], color=color, linestyle=&#39;dashed&#39;, label=&#39;y%d pred&#39; % i)
        return ax</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="skygp.gaussian_emulator.GaussianEmulator.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, x_train, y_train)</span>
</code></dt>
<dd>
<section class="desc"><p>This trains the Gaussian emulator from <code>x_train</code> and <code>y_train</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x_train</code></strong> :&ensp;<code>numpy</code> <code>array</code>, <code>shape</code> (<code>n_train</code>, <code>n_inputs</code>)</dt>
<dd>An array containing the inputs of training set.</dd>
<dt><strong><code>y_train</code></strong> :&ensp;<code>numpy</code> <code>array</code>, <code>shape</code> (<code>n_train</code>, <code>n_outputs</code>)</dt>
<dd>An array containing the outputs of training set.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, x_train, y_train):
    &#34;&#34;&#34;This trains the Gaussian emulator from `x_train` and `y_train`.

    Parameters:
        x_train : numpy array, shape (n_train, n_inputs)
            An array containing the inputs of training set.

        y_train : numpy array, shape (n_train, n_outputs)
            An array containing the outputs of training set.

    &#34;&#34;&#34;
    if not isinstance(x_train, np.ndarray):
        raise TypeError(&#39;x_train must be a numpy array.&#39;)
    if not isinstance(y_train, np.ndarray):
        raise TypeError(&#39;y_train must be a numpy array.&#39;)
    if x_train.ndim != 2:
        raise ValueError(&#39;x_train must be two-dimensional.&#39;)
    if y_train.ndim != 2:
        raise ValueError(&#39;y_train must be two-dimensional.&#39;)

    self.x_train = np.copy(x_train)
    self.y_train = np.copy(y_train)
    self.regressor.fit(self.x_train, self.y_train)</code></pre>
</details>
</dd>
<dt id="skygp.gaussian_emulator.GaussianEmulator.inspect_training_xslice"><code class="name flex">
<span>def <span class="ident">inspect_training_xslice</span></span>(<span>self, xslice, ax=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Plot to compare the emulator's predictions against training data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>xslice</code></strong> :&ensp;<code>int</code></dt>
<dd>The component of <code>self.x_train</code> to be plotted.</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.axes._subplots.AxesSubplot</code> <em>optional</em></dt>
<dd>The matplotlib axe to be plotted.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.axes._subplots.AxesSubplot</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="examples">Examples:</h2>
<p>After we have trained the <a title="skygp.gaussian_emulator.GaussianEmulator" href="#skygp.gaussian_emulator.GaussianEmulator"><code>GaussianEmulator</code></a>, we may inspect the
training results as below:</p>
<pre><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import gaussian_emulator as gmu
&gt;&gt;&gt; emulator = gmu.GaussianEmulator()
&gt;&gt;&gt; x_train = np.array([[0.0], [1.0]])
&gt;&gt;&gt; y_train = np.array([[0.0], [2.0]])
&gt;&gt;&gt; emulator.fit(x_train, y_train)
&gt;&gt;&gt; emulator.inspect_training_xslice(0)
&lt;matplotlib.axes._subplots.AxesSubplot object at 0x...&gt;
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def inspect_training_xslice(self, xslice, ax=None):
    &#34;&#34;&#34;Plot to compare the emulator&#39;s predictions against training data.

    Parameters:
        xslice : int
            The component of `self.x_train` to be plotted.

        ax : matplotlib.axes._subplots.AxesSubplot *optional*
            The matplotlib axe to be plotted.

    Returns:
        ax : matplotlib.axes._subplots.AxesSubplot

    Examples:
    ----------
    After we have trained the `GaussianEmulator`, we may inspect the
    training results as below:

    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; import gaussian_emulator as gmu
    &gt;&gt;&gt; emulator = gmu.GaussianEmulator()
    &gt;&gt;&gt; x_train = np.array([[0.0], [1.0]])
    &gt;&gt;&gt; y_train = np.array([[0.0], [2.0]])
    &gt;&gt;&gt; emulator.fit(x_train, y_train)
    &gt;&gt;&gt; emulator.inspect_training_xslice(0)
    &lt;matplotlib.axes._subplots.AxesSubplot object at 0x...&gt;

    &#34;&#34;&#34;
    if not isinstance(xslice, int):
        raise TypeError(&#39;xslice must be an integer.&#39;)
    if ax is not None and not isinstance(ax, mpl.axes.Axes):
        raise TypeError(&#39;ax must be a matplotlib.axes.Axes object.&#39;)

    # create ax if not being passed
    if ax is None:
        _, ax = plt.subplots()

    # sort training data by i_slice
    argsort = np.argsort(self.x_train[:, xslice])
    x_train_sorted = self.x_train[argsort]
    y_train_sorted = self.y_train[argsort]

    y_pred = self.predict(x_train_sorted)
    n_outputs = y_train_sorted.shape[1]
    for i in range(n_outputs):
        if n_outputs &gt; 1:
            color = plt.cm.jet(1.0 * i/(n_outputs-1))
        else:
            color = plt.cm.jet(1.0)
        x_slice = x_train_sorted[:, xslice]
        ax.scatter(x_slice, y_train_sorted[:, i], color=color, label=&#39;y%d true&#39; % i)
        ax.plot(x_slice, y_pred[:, i], color=color, linestyle=&#39;dashed&#39;, label=&#39;y%d pred&#39; % i)
    return ax</code></pre>
</details>
</dd>
<dt id="skygp.gaussian_emulator.GaussianEmulator.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, x_test)</span>
</code></dt>
<dd>
<section class="desc"><p>This returns the prediction.</p>
<p>This is essentially the emulator function when training has
been done to a satisfactory level.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x_test</code></strong> :&ensp;<code>numpy</code> <code>array</code>, <code>shape</code> (<code>n_train</code>, <code>n_inputs</code>)</dt>
<dd>An array containing the inputs of interest.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>y_pred</code></strong> :&ensp;<code>numpy</code> <code>array</code>, <code>shape</code> (<code>n_train</code>, <code>n_outputs</code>)</dt>
<dd>An array containing the outputs predicted by the emulator.
When training is done correctly, this prediction should be
very close to the actual outputs, and hence can be used to
emulator the actual computation that is usually time
consuming.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, x_test):
    &#34;&#34;&#34;This returns the prediction.

    This is essentially the emulator function when training has
    been done to a satisfactory level.

    Parameters:
        x_test : numpy array, shape (n_train, n_inputs)
            An array containing the inputs of interest.

    Returns:
        y_pred : numpy array, shape (n_train, n_outputs)
            An array containing the outputs predicted by the emulator.
            When training is done correctly, this prediction should be
            very close to the actual outputs, and hence can be used to
            emulator the actual computation that is usually time
            consuming.

    &#34;&#34;&#34;
    if not isinstance(x_test, np.ndarray):
        raise TypeError(&#39;x_test must be a numpy array.&#39;)

    y_pred = self.regressor.predict(x_test)
    return y_pred</code></pre>
</details>
</dd>
<dt id="skygp.gaussian_emulator.GaussianEmulator.set_niterations"><code class="name flex">
<span>def <span class="ident">set_niterations</span></span>(<span>self, n_itr)</span>
</code></dt>
<dd>
<section class="desc"><p>This sets the number of training iterations.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n_itr</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of training iterations.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_niterations(self, n_itr):
    &#34;&#34;&#34;This sets the number of training iterations.

    Parameters:
        n_itr : int
            The number of training iterations.
    &#34;&#34;&#34;
    if not isinstance(n_itr, int):
        raise TypeError(&#39;n_itr must be an integer.&#39;)

    self.regressor.n_restarts_optimizer = n_itr</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="skygp" href="index.html">skygp</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="skygp.gaussian_emulator.GaussianEmulator" href="#skygp.gaussian_emulator.GaussianEmulator">GaussianEmulator</a></code></h4>
<ul class="">
<li><code><a title="skygp.gaussian_emulator.GaussianEmulator.fit" href="#skygp.gaussian_emulator.GaussianEmulator.fit">fit</a></code></li>
<li><code><a title="skygp.gaussian_emulator.GaussianEmulator.inspect_training_xslice" href="#skygp.gaussian_emulator.GaussianEmulator.inspect_training_xslice">inspect_training_xslice</a></code></li>
<li><code><a title="skygp.gaussian_emulator.GaussianEmulator.predict" href="#skygp.gaussian_emulator.GaussianEmulator.predict">predict</a></code></li>
<li><code><a title="skygp.gaussian_emulator.GaussianEmulator.set_niterations" href="#skygp.gaussian_emulator.GaussianEmulator.set_niterations">set_niterations</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.2</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>